# **JOURS 58-60 : PROJET INTERM√âDIAIRE KUBERNETES** üöÄ

## **üéØ OBJECTIF DU PROJET**
Migrer une application compl√®te de Docker Compose vers Kubernetes, en appliquant toutes les comp√©tences acquises pendant la semaine 9 (Auto-scaling, Health Checks, Self-Healing).

**Dur√©e :** 3 jours

---

## **üìä ARCHITECTURE MIGR√âE**

### **üîß Services Docker Compose ‚Üí Kubernetes**
| Service Docker            | √âquivalent Kubernetes | Type      | Sp√©cificit√©s                          |
|---------------------------|-----------------------|-----------|---------------------------------------|
| **PostgreSQL**            | StatefulSet           | Stateful  | PersistentVolume, ConfigMap, Secret   |
| **Spring Boot Backend**   | Deployment            | Stateless | HPA, Health Checks, ConfigMap         |
| **Angular Frontend**      | Deployment            | Stateless | HPA, ConfigMap, Ingress               |
| **SMTP4Dev**              | Deployment            | Stateless | Service ClusterIP                     |

### **üèóÔ∏è Architecture Kubernetes Finale**
```
NAMESPACE: evote
‚îú‚îÄ‚îÄ üì¶ StatefulSet: postgres-db
‚îÇ   ‚îú‚îÄ‚îÄ üîê Secret: credentials
‚îÇ   ‚îú‚îÄ‚îÄ üìÑ ConfigMap: configuration
‚îÇ   ‚îî‚îÄ‚îÄ üíæ PersistentVolumeClaim: data-storage
‚îÇ
‚îú‚îÄ‚îÄ üì¶ Deployment: backend-spring
‚îÇ   ‚îú‚îÄ‚îÄ üîÑ HPA: auto-scaling (CPU 70%, Memory 80%)
‚îÇ   ‚îú‚îÄ‚îÄ üè• Probes: liveness + readiness
‚îÇ   ‚îú‚îÄ‚îÄ üìÑ ConfigMap: app properties
‚îÇ   ‚îî‚îÄ‚îÄ üîó Service: backend-service (ClusterIP)
‚îÇ
‚îú‚îÄ‚îÄ üì¶ Deployment: frontend-angular  
‚îÇ   ‚îú‚îÄ‚îÄ üîÑ HPA: auto-scaling (CPU 60%, Memory 70%)
‚îÇ   ‚îú‚îÄ‚îÄ üè• Probes: simple HTTP checks
‚îÇ   ‚îú‚îÄ‚îÄ üìÑ ConfigMap: environment
‚îÇ   ‚îî‚îÄ‚îÄ üîó Service: frontend-service (ClusterIP)
‚îÇ
‚îú‚îÄ‚îÄ üì¶ Deployment: smtp-server
‚îÇ   ‚îî‚îÄ‚îÄ üîó Service: smtp-service (ClusterIP)
‚îÇ
‚îî‚îÄ‚îÄ üåê Ingress: evote-ingress
    ‚îú‚îÄ‚îÄ üìç / ‚Üí frontend-service
    ‚îú‚îÄ‚îÄ üìç /api ‚Üí backend-service
    ‚îî‚îÄ‚îÄ üìç /smtp ‚Üí smtp-service
```

---

## **üõ†Ô∏è COMP√âTENCES APPLIQU√âES**

### **‚úÖ De la Semaine 9 (Jours 53-57)**
1. **Auto-Scaling (HPA)** : Configur√© sur backend et frontend
2. **Health Checks** : Liveness + Readiness probes sur tous les services
3. **Self-Healing** : Red√©marrage auto, isolation des pannes
4. **Monitoring** : Metrics Server pour HPA

### **‚úÖ Des Semaines Pr√©c√©dentes**
1. **Services & Networking** : Services ClusterIP, Ingress
2. **Configuration** : ConfigMaps et Secrets
3. **Storage** : PersistentVolumes pour la base de donn√©es
4. **D√©ploiement** : Deployments avec rolling updates

---

## **üìÅ STRUCTURE DES FICHIERS CR√â√âS**

```
e-vote-k8s/
‚îú‚îÄ‚îÄ üìÇ 00-namespace/              # Isolation logique
‚îÇ   ‚îî‚îÄ‚îÄ namespace.yaml
‚îÇ
‚îú‚îÄ‚îÄ üìÇ 01-configuration/          # Configuration non sensible
‚îÇ   ‚îú‚îÄ‚îÄ backend-configmap.yaml
‚îÇ   ‚îú‚îÄ‚îÄ frontend-configmap.yaml
‚îÇ   ‚îî‚îÄ‚îÄ database-configmap.yaml
‚îÇ
‚îú‚îÄ‚îÄ üìÇ 02-secrets/                # Donn√©es sensibles
‚îÇ   ‚îú‚îÄ‚îÄ database-secret.yaml
‚îÇ   ‚îî‚îÄ‚îÄ backend-secret.yaml
‚îÇ
‚îú‚îÄ‚îÄ üìÇ 03-storage/                # Persistance donn√©es
‚îÇ   ‚îú‚îÄ‚îÄ postgres-pv.yaml
‚îÇ   ‚îî‚îÄ‚îÄ postgres-pvc.yaml
‚îÇ
‚îú‚îÄ‚îÄ üìÇ 04-database/               # Service stateful
‚îÇ   ‚îú‚îÄ‚îÄ postgres-statefulset.yaml
‚îÇ   ‚îî‚îÄ‚îÄ postgres-service.yaml
‚îÇ
‚îú‚îÄ‚îÄ üìÇ 05-backend/                # Microservice Spring Boot
‚îÇ   ‚îú‚îÄ‚îÄ backend-deployment.yaml
‚îÇ   ‚îú‚îÄ‚îÄ backend-service.yaml
‚îÇ   ‚îî‚îÄ‚îÄ backend-hpa.yaml
‚îÇ
‚îú‚îÄ‚îÄ üìÇ 06-frontend/               # Application Angular
‚îÇ   ‚îú‚îÄ‚îÄ frontend-deployment.yaml
‚îÇ   ‚îú‚îÄ‚îÄ frontend-service.yaml
‚îÇ   ‚îî‚îÄ‚îÄ frontend-hpa.yaml
‚îÇ
‚îú‚îÄ‚îÄ üìÇ 07-smtp/                   Service mail de test
‚îÇ   ‚îú‚îÄ‚îÄ smtp-deployment.yaml
‚îÇ   ‚îî‚îÄ‚îÄ smtp-service.yaml
‚îÇ
‚îú‚îÄ‚îÄ üìÇ 08-networking/             # Exposition externe
‚îÇ   ‚îî‚îÄ‚îÄ ingress.yaml
‚îÇ
‚îú‚îÄ‚îÄ üìÇ 09-monitoring/             # Observabilit√©
‚îÇ   ‚îî‚îÄ‚îÄ service-monitor.yaml
‚îÇ
‚îú‚îÄ‚îÄ üöÄ deploy.sh                  # Script de d√©ploiement
‚îú‚îÄ‚îÄ üìã README.md                  # Documentation
‚îî‚îÄ‚îÄ üîß kustomization.yaml         # Gestion des versions (optionnel)
```

---

## **üîç PROBL√àMES RENCONTR√âS ET SOLUTIONS**

### **1. Ingress Controller Non Disponible**
**Probl√®me :** `Error creating ingress resource`
**Solution :** Installation manuelle de Nginx Ingress Controller
```bash
# Sur Minikube
minikube addons enable ingress

# V√©rification
kubectl get pods -n ingress-nginx
```

### **2. Images Priv√©es Docker Hub**
**Probl√®me :** `ImagePullBackOff` pour les images priv√©es
**Solution :** Cr√©ation d'un secret Docker Registry
```yaml
# Dans les Deployments
spec:
  template:
    spec:
      imagePullSecrets:
      - name: dockerhub-secret
```

### **3. Connexion Base de Donn√©es**
**Probl√®me :** Backend ne peut pas se connecter √† PostgreSQL
**Solution :** Utilisation des Services DNS Kubernetes
```yaml
# ConfigMap backend
data:
  SPRING_DATASOURCE_URL: jdbc:postgresql://postgres-service.evote.svc.cluster.local:5432/evote
```

### **4. HPA Sans M√©triques**
**Probl√®me :** `HPA unable to fetch metrics`
**Solution :** Activation de Metrics Server
```bash
minikube addons enable metrics-server
kubectl top pods -n evote
```

---

## **üéØ BONNES PRATIQUES IMPL√âMENT√âES**

### **1. S√©paration des Pr√©occupations**
- **Namespace d√©di√©** : Isolation logique de l'application
- **ConfigMaps vs Secrets** : S√©paration configuration sensible/non sensible
- **Services par composant** : D√©couplage des responsabilit√©s

### **2. Haute Disponibilit√©**
- **Multiples r√©plicas** : minReplicas: 2 sur les services critiques
- **Health Checks** : Liveness + Readiness probes
- **Rolling Updates** : Mise √† jour sans interruption

### **3. Auto-Scaling Optimal**
```yaml
# Backend HPA
metrics:
- type: Resource
  resource:
    name: cpu
    target:
      type: Utilization
      averageUtilization: 70
- type: Resource
  resource:
    name: memory
    target:
      type: Utilization
      averageUtilization: 80
behavior:
  scaleDown:
    stabilizationWindowSeconds: 300  # 5 minutes
```

### **4. S√©curit√©**
- **Secrets chiffr√©s** : Donn√©es sensibles en base64
- **Services ClusterIP** : Exposition interne uniquement
- **Ingress avec TLS** : Chiffrement des communications

---

## **üöÄ COMMANDES DE D√âPLOIEMENT**

### **D√©ploiement Complet**
```bash
# Appliquer tous les manifests
./deploy.sh

# Ou √©tape par √©tape
kubectl apply -f 00-namespace/
kubectl apply -f 01-configuration/
kubectl apply -f 02-secrets/
# ... etc pour chaque dossier
```

### **V√©rification**
```bash
# Voir l'√©tat global
kubectl get all -n evote

# Voir les √©v√©nements
kubectl get events -n evote --sort-by=.lastTimestamp

# V√©rifier les endpoints
kubectl get endpoints -n evote

# Tester l'application
curl http://evote.local
```

### **Monitoring**
```bash
# Voir l'utilisation des ressources
kubectl top pods -n evote
kubectl top nodes

# Surveiller les HPA
kubectl get hpa -n evote -w

# Voir les logs
kubectl logs -n evote -l app=backend --tail=50 -f
```

---

## **üìä √âQUIVALENCES DOCKER COMPOSE ‚Üî KUBERNETES**

| Concept Docker Compose | Concept Kubernetes | Avantage Kubernetes |
|------------------------|-------------------|---------------------|
| `services:` | `Deployment` + `Service` | Scaling auto, health checks |
| `environment:` | `ConfigMap` + `Secret` | S√©paration config/sensible |
| `volumes:` | `PersistentVolumeClaim` | Abstraction stockage |
| `ports:` | `Service` + `Ingress` | Load balancing avanc√© |
| `depends_on:` | Readiness Probes | D√©tection automatique |
| `restart: always` | Liveness Probes | Self-healing intelligent |
| `scale:` | `HorizontalPodAutoscaler` | Auto-scaling dynamique |

---

## **üîê GESTION DES SECRETS**

**Approche s√©curis√©e :**
```bash
# Ne JAMAIS commiter en clair
# Utiliser des outils comme SealedSecrets ou Vault en production

# Pour le d√©veloppement
kubectl create secret generic db-secret \
  --from-literal=password='1234' \
  --namespace=evote \
  --dry-run=client \
  -o yaml > database-secret.yaml
```

---

## **üåê ACC√àS √Ä L'APPLICATION**

### **Via Ingress (Production)**
```bash
# Ajouter au hosts local
echo "$(minikube ip) evote.local" | sudo tee -a /etc/hosts

# URLs
http://evote.local          # Frontend
http://evote.local/api      # Backend API
http://evote.local/api/actuator/health  # Health checks
```

### **Via Port-Forward (D√©veloppement)**
```bash
# Acc√®s direct aux services
kubectl port-forward service/frontend-service 8080:80 -n evote
# http://localhost:8080

kubectl port-forward service/backend-service 8081:8080 -n evote
# http://localhost:8081
```

---

## **üìà M√âTRICS ET MONITORING**

### **Metrics Server**
```bash
# Activation
minikube addons enable metrics-server

# V√©rification
kubectl get apiservices | grep metrics
kubectl top nodes
```

### **M√©triques Collect√©es**
- **Utilisation CPU/M√©moire** : Pour HPA
- **Restart counts** : Indicateur de stabilit√©
- **Ready pods** : Pour d√©cisions de scaling
- **Endpoint changes** : Pour disponibilit√©

---

## **üßπ NETTOYAGE**

```bash
# Supprimer l'application compl√®te
kubectl delete namespace evote

# Supprimer les volumes persistants
kubectl delete pv --all

# R√©initialiser Minikube (si n√©cessaire)
minikube stop
minikube delete
minikube start
```

---

## **üéØ LE√áONS APPRISES**

### **1. Kubernetes ‚â† Docker Compose**
- **Architecture diff√©rente** : Plus de composants, plus de flexibilit√©
- **D√©claration vs Ex√©cution** : Kubernetes g√®re l'√©tat d√©sir√©
- **R√©silience int√©gr√©e** : Self-healing, auto-scaling, rolling updates

### **2. Importance des Health Checks**
- **Sans probes** : Kubernetes ne sait pas si l'app fonctionne
- **Readiness critique** : Pour le routing Ingress et HPA
- **Startup n√©cessaire** : Pour les apps lentes (Spring Boot)

### **3. Auto-Scaling Pratique**
- **HPA simple √† configuer** : Bas√© sur CPU/m√©moire
- **Impact des probes** : Seuls les pods "ready" comptent
- **Stabilisation importante** : √âviter le thrashing

### **4. Debug Indispensable**
- `kubectl describe` : Comprendre les probl√®mes
- `kubectl logs` : Voir ce qui se passe
- `kubectl get events` : Chronologie des √©v√©nements

---

## **üöÄ PROCHAINES √âTAPES POSSIBLES**

### **Pour la Production**
- [ ] **Helm Charts** : Packaging et gestion des versions
- [ ] **Cert-manager** : Certificats TLS automatiques
- [ ] **Prometheus + Grafana** : Monitoring avanc√©
- [ ] **ArgoCD** : GitOps pour d√©ploiements
- [ ] **Network Policies** : S√©curit√© r√©seau fine
- [ ] **PodDisruptionBudget** : HA pendant maintenance

### **Am√©liorations**
- [ ] **Resource Quotas** : Limiter l'utilisation ressources
- [ ] **Affinity/Anti-affinity** : R√©partition optimale des pods
- [ ] **Custom Metrics HPA** : Scaling bas√© sur m√©triques m√©tier
- [ ] **Service Mesh** : Istio/Linkerd pour observabilit√© avanc√©e
- [ ] **Chaos Engineering** : Tests de r√©silience proactifs

---

## **üìä BILAN DES 3 JOURS**

### **‚úÖ ACCOMPLISSEMENTS**
- ‚úÖ **Migration compl√®te** Docker Compose ‚Üí Kubernetes
- ‚úÖ **Architecture production-ready** avec tous les services
- ‚úÖ **Auto-scaling impl√©ment√©** sur services critiques
- ‚úÖ **Health checks avanc√©s** avec self-healing
- ‚úÖ **S√©curit√©** via Secrets et ConfigMaps
- ‚úÖ **Documentation compl√®te** et reproductible

### **üîß COMP√âTENCES D√âMONTR√âES**
- **D√©ploiement** : Deployments, Services, Ingress
- **Configuration** : ConfigMaps, Secrets
- **Stockage** : PersistentVolumes, StatefulSets
- **Auto-scaling** : HPA avec m√©triques ressources
- **R√©silience** : Health checks, rolling updates
- **Monitoring** : Metrics Server, logging, debugging

### **üéØ R√âSULTAT FINAL**
Une application compl√®te migr√©e vers Kubernetes, scalable, r√©siliente, observable et pr√™te pour le d√©ploiement en production. Toutes les comp√©tences des 57 premiers jours ont √©t√© appliqu√©es dans un projet concret et r√©aliste.

---

**üìå CONCLUSION** : Ce projet a consolid√© toutes les comp√©tences Kubernetes acquises jusqu'√† pr√©sent. L'application est maintenant d√©ployable sur n'importe quel cluster Kubernetes, avec auto-scaling, self-healing et une architecture professionnelle.

**#Kubernetes #Migration #DockerToK8s #ProductionReady #DevOps #CloudNative #Microservices #AutoScaling #SelfHealing**
